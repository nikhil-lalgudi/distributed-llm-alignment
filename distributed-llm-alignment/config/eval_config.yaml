seed: 2024
models:
  base: "mistralai/Mistral-7B-v0.1"
  sft: "checkpoints/sft/latest"
  dpo: "checkpoints/dpo/latest"
  distill: "checkpoints/distill/latest"

benchmarks:
  alignment_local:
    type: local
    prompts_path: "data/processed/eval_prompts.jsonl"
    max_samples: 512
  safety_hh:
    type: hf
    hf_path: "Anthropic/hh-rlhf"
    split: "train"
    prompt_key: "prompt"
    max_samples: 512
  truthfulness:
    type: local
    prompts_path: "data/processed/truthfulqa.jsonl"
    max_samples: 256

latency:
  hardware: "A100-80GB"
  batch_sizes: [1, 4, 8]
  seq_lengths: [256, 512, 1024]
  warmup_steps: 5
  measure_steps: 20

generation:
  max_new_tokens: 256
  temperature: 0.7
  top_p: 0.9
  do_sample: true

logging:
  output_path: "logs/eval/results.json"
  table_path: "logs/eval/summary.md"
